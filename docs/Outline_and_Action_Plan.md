# Outline and Action Plan

1. Get the Data
    * BeerAdvocate Dataset from Kaggle
    * API's 
        * Google
        * Yelp
        * Facebook
        * Foursquare
        * Untappd
    * Webscraping
        * Beautiful Soup
        * Selenium
        * Scrapy
2. Store the Data
    * SQL and Postgres
    * MongoDB
3. Explore the Data
    * EDA in Pandas
4. Combine, Clean, and Organize the Data
    * More Pandas
5. Visualize the Data
    * Matplotlib
    * Folium or maybe Plotly for Nicer Geographic Maps
6. Ask Questions of the Data
    * At least 1 official Hypothesis Test


## Reminders
* Focus on MVP. Create Pipeline of classes and functions that automate as mush of the above Action Plan as possible.
* Don't get stuck in data acquisition. Get 1 API working and 1 Webscrape working. Max
* Spend most of my class time focused on value add work like README additions and improvements and python coding. Research can be focused on during off time if I'm still interested.
* Remember to save time for smoothing out the final project. README touch ups, presentation outline and practice, pycodestyle review, Github repo clean up and organization, etc.

## Expected Time Budget/Requirements
* Plotting - 1 Day
* Store Data - 1/3 Day
* Explore Data - 1/3 Day
* Clean, Combine, and Organize Data - 1/3 Day
* Get the Data - 1 Day
* Hypothesis Test - 1/2 Day
* README and Project Smoothing/Finalization - 1/2 Day

## Monday Goals
* README Draft 1 - Questions to Answer - Introduction - **0%**
* Explore BeerAdvocate Data -  **50%**
* Get 1 API Up and Running - **60%**
* Get 1 Webscrape Up and Running - **90%**
* Collect Data from above into MongoDB and/or Postgres - **25%**

## Tuesday Goals
* Question 2 Beginning to End - MVP complete
    * EDA, Cleaning, Organizing - **90%**
    * Plotting - **90%**
    * Hypothesis Test **95%**
    * README **0%**

## Wednesday Goals - Ended up pivoting to my MVP and saving the MVP+ for future work
* Before Noon
    * Determine Feasibility of MVP+ (API, Scraping Data)
    * EDA, Cleaning, Data Combined and Mismatched Data Dealt With
* After Noon
    * Plotting
    * Hypothesis Test if necessary  
    **and/or**
    * README

## Thursday Goals